# Etapy projektu - Klasyfikacja flag paÅ„stw

## Wymagania systemowe

### Wersje oprogramowania:
- **Python:** 3.11 lub 3.12 (zalecane 3.11 dla lepszej kompatybilnoÅ›ci z TensorFlow)
- **TensorFlow:** >= 2.10.0
- **NumPy:** >= 1.22.0
- **Pillow:** >= 9.0.0
- **scikit-learn:** >= 1.0.0
- **matplotlib:** >= 3.5.0
- **seaborn:** >= 0.12.0
- **kagglehub:** >= 0.3.0
- **pandas:** >= 1.4.0 (opcjonalne)

**Uwaga:** Python 3.14 nie jest jeszcze wspierany przez TensorFlow. UÅ¼yj Python 3.11 lub 3.12.

### Wymagania sprzÄ™towe:
- **RAM:** Minimum 4GB (zalecane 8GB+)
- **Dysk:** ~1GB wolnego miejsca (dane + model)
- **GPU:** Opcjonalne (przyspiesza trening, ale nie jest wymagane)

---

## ğŸš€ INSTRUKCJA URUCHOMIENIA - KROK PO KROKU

### âš ï¸ WAÅ»NE: Przeczytaj przed rozpoczÄ™ciem!

**Dla osÃ³b uruchamiajÄ…cych projekt po raz pierwszy:** Ta sekcja zawiera wszystkie kroki potrzebne do uruchomienia projektu od zera. PostÄ™puj dokÅ‚adnie krok po kroku.

---

### ğŸ“‹ Wymagane pliki do uruchomienia:

Musisz mieÄ‡ nastÄ™pujÄ…ce pliki w projekcie:
- âœ… `train.py` - skrypt treningowy
- âœ… `evaluate.py` - skrypt ewaluacji (WAÅ»NE - nie zapomnij!)
- âœ… `model.py` - definicja modelu CNN
- âœ… `load_data.py` - wczytywanie i preprocessing danych
- âœ… `requirements.txt` - lista zaleÅ¼noÅ›ci (opcjonalne, ale pomocne)

### ğŸ¯ WaÅ¼na informacja o gotowym modelu:

**âœ… Gotowy model jest juÅ¼ w repozytorium!**

W folderze `models/` znajduje siÄ™ juÅ¼ wytrenowany model `best_model.h5` (accuracy: 98.97%), ktÃ³ry jest commitowany do repo.

**Oznacza to, Å¼e:**
- MoÅ¼esz od razu uruchomiÄ‡ `evaluate.py` bez treningu (jeÅ›li chcesz tylko zobaczyÄ‡ wyniki)
- Albo moÅ¼esz wytrenowaÄ‡ wÅ‚asny model uÅ¼ywajÄ…c `train.py` (nadpisze istniejÄ…cy model)
- Model jest gotowy do uÅ¼ycia i nie wymaga treningu

**JeÅ›li chcesz tylko zobaczyÄ‡ wyniki bez treningu:**
- PomiÅ„ Krok 4 (trening) i przejdÅº od razu do Kroku 5 (ewaluacja)
- Model `models/best_model.h5` jest juÅ¼ dostÄ™pny w repo

---

### ğŸ–¥ï¸ Opcja 1: Uruchomienie w Google Colab (ZALECANE - szybsze dziÄ™ki GPU)

#### Krok 1: Przygotowanie Å›rodowiska Colab
1. OtwÃ³rz [Google Colab](https://colab.research.google.com/)
2. UtwÃ³rz nowy notebook: **File â†’ New notebook**
3. **WAÅ»NE:** WÅ‚Ä…cz GPU: **Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU â†’ Save**
   - Bez GPU trening bÄ™dzie trwaÅ‚ ~75 minut, z GPU ~5-10 minut

#### Krok 2: Instalacja zaleÅ¼noÅ›ci
W pierwszej komÃ³rce notebooka uruchom:
```python
!pip install kagglehub tensorflow matplotlib scikit-learn pillow numpy seaborn
```
**Uwaga:** Instalacja moÅ¼e chwilÄ™ potrwaÄ‡. Poczekaj aÅ¼ zakoÅ„czy siÄ™ (âœ“).

#### Krok 3: Upload plikÃ³w projektu
**WAÅ»NE:** Musisz wgraÄ‡ WSZYSTKIE 4 pliki:
1. Kliknij ikonÄ™ folderu (ğŸ“ Files) po lewej stronie
2. Kliknij **Upload to session storage**
3. Wybierz i wgraj nastÄ™pujÄ…ce pliki:
   - âœ… `train.py`
   - âœ… `evaluate.py` â† **NIE ZAPOMNIJ TEGO!**
   - âœ… `model.py`
   - âœ… `load_data.py`

**Uwaga:** Pliki muszÄ… byÄ‡ w folderze `/content/` w Colab. SprawdÅº czy wszystkie 4 pliki sÄ… widoczne w panelu Files.

#### Krok 4: Uruchomienie treningu (OPCJONALNE)

**â„¹ï¸ UWAGA:** JeÅ›li chcesz tylko zobaczyÄ‡ wyniki, moÅ¼esz pominÄ…Ä‡ ten krok! Gotowy model `models/best_model.h5` jest juÅ¼ w repo i moÅ¼esz od razu przejÅ›Ä‡ do Kroku 5 (ewaluacja).

JeÅ›li chcesz wytrenowaÄ‡ wÅ‚asny model (lub nadpisaÄ‡ istniejÄ…cy), uruchom:
```python
!python /content/train.py
```

**Co siÄ™ dzieje podczas treningu:**
- Pobieranie danych z Kaggle (~500 MB, moÅ¼e chwilÄ™ potrwaÄ‡)
- Wczytywanie i preprocessing obrazÃ³w (14,625 obrazÃ³w)
- Budowa modelu CNN (5.3M parametrÃ³w)
- Trening modelu (11 epok, ~5-10 minut na GPU)
- Generowanie wykresÃ³w treningowych (6 wykresÃ³w)

**Oczekiwany wynik:**
- Model zapisany: `models/best_model.h5`
- Najlepsza val_accuracy: ~98.97% (epoka 6)
- 6 wykresÃ³w w folderze `plots/`:
  - `training_history.png` - accuracy i loss
  - `classification_error.png` - bÅ‚Ä…d klasyfikacji
  - `learning_rate_evolution.png` - ewolucja LR
  - `loss_per_class.png` - loss per class
  - `weight_trajectories.png` - trajektorie wag
  - `gradient_norms.png` - normy gradientÃ³w

#### Krok 5: Uruchomienie ewaluacji
**WAÅ»NE:** Po zakoÅ„czeniu treningu uruchom ewaluacjÄ™ w nowej komÃ³rce:
```python
!python /content/evaluate.py
```

**Co siÄ™ dzieje podczas ewaluacji:**
- Wczytywanie modelu `models/best_model.h5`
- Ewaluacja na zbiorze testowym (2,925 obrazÃ³w)
- Generowanie wykresÃ³w ewaluacyjnych (9 wykresÃ³w)
- Generowanie raportÃ³w tekstowych (3 pliki .txt)

**Oczekiwany wynik:**
- Test Accuracy: ~98.97%
- Top-3 Accuracy: 100.00%
- 9 wykresÃ³w w folderze `plots/`:
  - `confusion_matrix_top_classes.png`
  - `error_examples.png`
  - `top_n_accuracy.png`
  - `confidence_distribution.png`
  - `precision_recall_per_class.png`
  - `error_confusion_matrix.png`
  - (i inne)
- 3 pliki tekstowe z wynikami:
  - `classification_report.txt` - szczegÃ³Å‚owe metryki
  - `error_analysis.txt` - analiza bÅ‚Ä™dÃ³w
  - `confusion_matrix.txt` - surowe dane

#### Krok 6: Pobieranie wynikÃ³w
Po zakoÅ„czeniu treningu i ewaluacji:

1. **Pobierz model:**
   - Files â†’ `models/best_model.h5` â†’ prawy przycisk â†’ Download

2. **Pobierz wszystkie wykresy:**
   - Files â†’ `plots/` â†’ zaznacz wszystkie pliki PNG â†’ Download
   - Powinno byÄ‡ 15 wykresÃ³w (6 z treningu + 9 z ewaluacji)

3. **Pobierz raporty tekstowe:**
   - Files â†’ `plots/` â†’ zaznacz pliki `.txt` â†’ Download
   - Powinno byÄ‡ 3 pliki tekstowe

**âš ï¸ UWAGA:** Dane w Colab sÄ… przechowywane tylko podczas sesji. Po zamkniÄ™ciu notebooka wszystko znika! Pobierz wyniki przed zamkniÄ™ciem.

---

### ğŸ’» Opcja 2: Uruchomienie lokalnie (na wÅ‚asnym komputerze)

#### Krok 1: Przygotowanie Å›rodowiska
1. UtwÃ³rz i aktywuj Å›rodowisko wirtualne:
   - **Windows:** 
     ```powershell
     py -3.11 -m venv .venv
     .\.venv\Scripts\Activate.ps1
     ```
   - **Linux/Mac:**
     ```bash
     python3.11 -m venv .venv
     source .venv/bin/activate
     ```

2. Zainstaluj zaleÅ¼noÅ›ci:
   ```bash
   pip install -r requirements.txt
   ```
   Lub rÄ™cznie:
   ```bash
   pip install kagglehub tensorflow matplotlib scikit-learn pillow numpy seaborn
   ```

#### Krok 2: Weryfikacja Å›rodowiska
Uruchom testy, aby sprawdziÄ‡ czy wszystko dziaÅ‚a:
```bash
python test_etap1.py    # Test pobierania danych
python model.py         # Test budowy modelu
```

#### Krok 3: Trening modelu (OPCJONALNE)

**â„¹ï¸ UWAGA:** JeÅ›li chcesz tylko zobaczyÄ‡ wyniki, moÅ¼esz pominÄ…Ä‡ ten krok! Gotowy model `models/best_model.h5` jest juÅ¼ w repo i moÅ¼esz od razu przejÅ›Ä‡ do Kroku 4 (ewaluacja).

JeÅ›li chcesz wytrenowaÄ‡ wÅ‚asny model (lub nadpisaÄ‡ istniejÄ…cy):
```bash
python train.py
```

**Czas treningu:** ~75 minut na CPU (bez GPU), ~5-10 minut z GPU

#### Krok 4: Ewaluacja modelu
```bash
python evaluate.py
```

**Wyniki:** Wszystkie pliki zostanÄ… zapisane w folderze `plots/` i `models/`

---

### ğŸ“Š Podsumowanie wygenerowanych plikÃ³w

Po peÅ‚nym uruchomieniu (trening + ewaluacja) powinieneÅ› mieÄ‡:

**W folderze `models/`:**
- âœ… `best_model.h5` - wytrenowany model
  - **â„¹ï¸ UWAGA:** Ten model jest juÅ¼ commitowany do repo! JeÅ›li nie trenujesz wÅ‚asnego modelu, uÅ¼yjesz gotowego modelu z repo (accuracy: 98.97%)

**W folderze `plots/` - wykresy treningowe (6 plikÃ³w):**
- âœ… `training_history.png` - accuracy i loss przez epoki
- âœ… `classification_error.png` - bÅ‚Ä…d klasyfikacji (1-accuracy)
- âœ… `learning_rate_evolution.png` - ewolucja learning rate
- âœ… `loss_per_class.png` - loss dla wybranych klas
- âœ… `weight_trajectories.png` - trajektorie wag warstwy wyjÅ›ciowej
- âœ… `gradient_norms.png` - normy gradientÃ³w przez epoki

**W folderze `plots/` - wykresy ewaluacyjne (9 plikÃ³w):**
- âœ… `confusion_matrix_top_classes.png` - confusion matrix (top 50 klas)
- âœ… `error_examples.png` - przykÅ‚ady bÅ‚Ä™dnych klasyfikacji
- âœ… `top_n_accuracy.png` - Top-N accuracy (N=1-5)
- âœ… `confidence_distribution.png` - rozkÅ‚ad pewnoÅ›ci modelu
- âœ… `precision_recall_per_class.png` - Precision/Recall per class
- âœ… `error_confusion_matrix.png` - pary klas najczÄ™Å›ciej mylonych
- (i inne)

**W folderze `plots/` - raporty tekstowe (3 pliki):**
- âœ… `classification_report.txt` - szczegÃ³Å‚owe metryki per class
- âœ… `error_analysis.txt` - analiza najtrudniejszych klas
- âœ… `confusion_matrix.txt` - surowe dane confusion matrix

**ÅÄ…cznie: 1 model + 15 wykresÃ³w + 3 raporty = 19 plikÃ³w wynikowych**

---

### âš ï¸ CzÄ™ste problemy i rozwiÄ…zania

**Problem 1: "ModuleNotFoundError: No module named 'seaborn'"**
- **RozwiÄ…zanie:** Dodaj `seaborn` do instalacji: `!pip install seaborn`

**Problem 2: "Model nie znaleziony" podczas ewaluacji**
- **RozwiÄ…zanie:** Upewnij siÄ™, Å¼e najpierw uruchomiÅ‚eÅ› `train.py` i model zostaÅ‚ zapisany

**Problem 3: "max_samples_per_class mismatch"**
- **RozwiÄ…zanie:** Upewnij siÄ™, Å¼e w `train.py` i `evaluate.py` jest ta sama wartoÅ›Ä‡ (obecnie 75)

**Problem 4: Trening trwa bardzo dÅ‚ugo**
- **RozwiÄ…zanie:** UÅ¼yj GPU w Colab (Runtime â†’ Change runtime type â†’ GPU)

**Problem 5: Brakuje niektÃ³rych wykresÃ³w**
- **RozwiÄ…zanie:** Upewnij siÄ™, Å¼e uruchomiÅ‚eÅ› zarÃ³wno `train.py` (6 wykresÃ³w) jak i `evaluate.py` (9 wykresÃ³w)

---

### ğŸ“ Notatki dla kolegÃ³w

- **Gotowy model w repo:** Model `models/best_model.h5` jest juÅ¼ commitowany - moÅ¼esz uÅ¼yÄ‡ go bez treningu!
- **Opcjonalny trening:** JeÅ›li chcesz wytrenowaÄ‡ wÅ‚asny model, uruchom `train.py` (nadpisze istniejÄ…cy model)
- **Ewaluacja bez treningu:** MoÅ¼esz od razu uruchomiÄ‡ `evaluate.py` uÅ¼ywajÄ…c gotowego modelu z repo
- **Nie modyfikuj** `max_samples_per_class` bez aktualizacji w obu plikach (`train.py` i `evaluate.py`)
- **JeÅ›li trenujesz:** Zawsze uruchamiaj najpierw `train.py`, potem `evaluate.py`
- **Pobierz wszystkie pliki** z Colab przed zamkniÄ™ciem sesji
- **SprawdÅº** czy wszystkie 4 pliki sÄ… w Colab przed uruchomieniem

---

## Pierwsze uruchomienie â€“ krÃ³tkie instrukcje (stara sekcja)

### Lokalnie (na wÅ‚asnym komputerze):
1. UtwÃ³rz i aktywuj Å›rodowisko: 
   - Windows: `py -3.11 -m venv .venv` oraz `.\.venv\Scripts\Activate.ps1`
   - Linux/Mac: `python3.11 -m venv .venv` oraz `source .venv/bin/activate`
2. Zainstaluj zaleÅ¼noÅ›ci: `pip install -r requirements.txt`.
3. Uruchom `test_etap1.py`, aby pobraÄ‡ dane i potwierdziÄ‡, Å¼e pipeline dziaÅ‚a (to normalne, Å¼e pobieranie zajmuje ~500â€¯MB i chwilÄ™ trwa).
4. Uruchom `model.py` (lub `test_model.py`), Å¼eby sprawdziÄ‡, czy model buduje siÄ™ poprawnie.

*(Zobacz sekcjÄ™ "ğŸš€ INSTRUKCJA URUCHOMIENIA - KROK PO KROKU" powyÅ¼ej dla szczegÃ³Å‚owych instrukcji)*

## Cel projektu
Zbudowanie systemu klasyfikacji obrazÃ³w flag paÅ„stw Å›wiata uÅ¼ywajÄ…c sieci neuronowych gÅ‚Ä™bokich. ZbiÃ³r danych zawiera 195 krajÃ³w, po okoÅ‚o 1001 obrazÃ³w na kraj.

## MVP - Minimalna wersja dziaÅ‚ajÄ…ca
System zdolny do klasyfikacji flag z dokÅ‚adnoÅ›ciÄ… powyÅ¼ej 50% na zbiorze testowym, z peÅ‚nym pipeline od pobrania danych do ewaluacji modelu.

---

## ETAP 1: Pobieranie i przygotowanie danych [ZREALIZOWANY]

### Zadania wykonane:
- Implementacja automatycznego pobierania danych z Kaggle (kagglehub)
- Wczytywanie obrazÃ³w z folderÃ³w zorganizowanych wedÅ‚ug krajÃ³w
- Preprocessing:
  - Konwersja do RGB
  - Zmiana rozmiaru do 128x128 pikseli
  - Normalizacja wartoÅ›ci pikseli do zakresu [0, 1]
- PodziaÅ‚ danych na zbiory: train (70%), validation (10%), test (20%)

### Pliki:
- `download_data.py` - pobieranie danych z Kaggle
- `load_data.py` - wczytywanie i preprocessing danych
- `requirements.txt` - lista zaleÅ¼noÅ›ci Python

### Status: ZakoÅ„czony

---

## ETAP 2: Projektowanie i implementacja modelu [ZREALIZOWANY]

### Zadania:
- Zaprojektowanie architektury CNN odpowiedniej dla 195 klas
- Implementacja modelu w TensorFlow/Keras
- WybÃ³r warstw:
  - Warstwy konwolucyjne (Conv2D)
  - Warstwy pooling (MaxPooling2D)
  - Warstwy dropout dla regularyzacji
  - Warstwy gÄ™ste (Dense)
  - Warstwa wyjÅ›ciowa z softmax
- Kompilacja modelu z odpowiednim optimizer i loss function
- Test czy model siÄ™ kompiluje i ma poprawny ksztaÅ‚t wyjÅ›ciowy

### Pliki:
- `model.py` - definicja architektury CNN + sekcja testowa w `__main__`
- `test_model.py` - sanity check ksztaÅ‚tu i softmaxu

### Kryteria sukcesu:
- Model kompiluje siÄ™ bez bÅ‚Ä™dÃ³w
- KsztaÅ‚t wyjÅ›ciowy: (batch_size, 195)
- Model gotowy do treningu

---

## ETAP 3: Trening modelu [ZREALIZOWANY]

### Zadania wykonane:
- âœ… Implementacja skryptu treningowego (`train.py`)
- âœ… Konfiguracja hiperparametrÃ³w:
  - Learning rate: `1e-3` (Adam optimizer) z **ReduceLROnPlateau** scheduler
  - Batch size: `32`
  - Maksymalna liczba epok: `30`
  - EarlyStopping patience: `5`
  - Liczba prÃ³bek na klasÄ™: `75` (zwiÄ™kszone z 50 dla lepszych wynikÃ³w)
- âœ… Implementacja callbacks:
  - **ModelCheckpoint** - zapisywanie najlepszego modelu (`models/best_model.h5`) na podstawie `val_accuracy`
  - **EarlyStopping** - zatrzymanie przy braku poprawy przez 5 epok, przywrÃ³cenie najlepszych wag
  - **ReduceLROnPlateau** - automatyczne zmniejszanie learning rate (factor=0.5, patience=3, min_lr=1e-6)
  - **TrainingMetricsCallback** - custom callback do zbierania metryk analitycznych
- âœ… Wizualizacja procesu uczenia (6 wykresÃ³w):
  - `training_history.png` - accuracy i loss (train vs validation)
  - `classification_error.png` - bÅ‚Ä…d klasyfikacji (1-accuracy)
  - `learning_rate_evolution.png` - ewolucja learning rate przez epoki
  - `loss_per_class.png` - loss dla wybranych klas przez epoki
  - `weight_trajectories.png` - trajektorie wag warstwy wyjÅ›ciowej
  - `gradient_norms.png` - normy gradientÃ³w przez epoki
- âœ… Zapis wytrenowanego modelu: `models/best_model.h5`

### Pliki:
- `train.py` - skrypt treningowy z funkcjami moduÅ‚owymi
- `models/best_model.h5` - wytrenowany model (najlepsza wersja)
- `plots/training_history.png` - wykresy historii treningu
- `plots/classification_error.png` - bÅ‚Ä…d klasyfikacji
- `plots/learning_rate_evolution.png` - ewolucja learning rate
- `plots/loss_per_class.png` - loss per class
- `plots/weight_trajectories.png` - trajektorie wag
- `plots/gradient_norms.png` - normy gradientÃ³w

### Wyniki treningu (aktualne):
- **Val accuracy:** 98.97% (epoka 6 - najlepsza)
- **Train accuracy:** ~97% (epoka 6)
- **Liczba epok:** 11 (zatrzymane przez EarlyStopping)
- **Czas treningu:** ~5-10 minut na GPU (Colab), ~75 minut na CPU (lokalnie)
- **ZbieÅ¼noÅ›Ä‡:** Szybka zbieÅ¼noÅ›Ä‡ od epoki 2-3, brak overfittingu
- **Learning Rate:** Zmniejszony z 0.001 do 0.0005 w epoce 9 (ReduceLROnPlateau)

### Parametry uÅ¼yte w treningu:
```python
batch_size=32
epochs=30
learning_rate=1e-3  # z ReduceLROnPlateau scheduler
patience=5
max_samples_per_class=75  # 14,625 obrazÃ³w (75 na klasÄ™ Ã— 195 klas)
use_augmentation=False  # wyÅ‚Ä…czona (testy pokazaÅ‚y spadek accuracy)
```

### Status: ZakoÅ„czony

---

## ETAP 4: Ewaluacja modelu [ZREALIZOWANY]

### Zadania wykonane:
- âœ… Ewaluacja na zbiorze testowym:
  - Obliczenie accuracy i loss
  - Confusion matrix
- âœ… Analiza bÅ‚Ä™dÃ³w:
  - KtÃ³re flagi sÄ… najtrudniejsze do rozpoznania
  - PrzykÅ‚ady bÅ‚Ä™dnych klasyfikacji
  - Wizualizacja confusion matrix
- âœ… Obliczenie metryk szczegÃ³Å‚owych:
  - Precision, Recall, F1-score per class
  - Top-3 accuracy

### Pliki:
- `evaluate.py` - skrypt ewaluacji
- **Wykresy ewaluacyjne (9 plikÃ³w):**
  - `confusion_matrix_top_classes.png` - wizualizacja confusion matrix (top 50 klas)
  - `error_examples.png` - przykÅ‚ady bÅ‚Ä™dnych klasyfikacji
  - `top_n_accuracy.png` - Top-N accuracy (N=1-5)
  - `confidence_distribution.png` - rozkÅ‚ad pewnoÅ›ci modelu (poprawne vs bÅ‚Ä™dne)
  - `precision_recall_per_class.png` - Precision/Recall per class (top 30 najtrudniejszych)
  - `error_confusion_matrix.png` - pary klas najczÄ™Å›ciej mylonych
  - (i inne)
- **Raporty tekstowe (3 pliki):**
  - `confusion_matrix.txt` - surowe dane confusion matrix
  - `error_analysis.txt` - analiza najtrudniejszych klas
  - `classification_report.txt` - szczegÃ³Å‚owy raport z metrykami per class

### Wyniki ewaluacji (aktualne):
- **Test Accuracy:** 98.97%
- **Test Loss:** 0.0264
- **Top-1 Accuracy:** 98.97%
- **Top-2 Accuracy:** 100.00% â­
- **Top-3 Accuracy:** 100.00%
- **Liczba bÅ‚Ä™dÃ³w:** 30 / 2925 (1.03%)
- **Metryki ogÃ³lne (macro average):**
  - Precision: 98.46%
  - Recall: 98.97%
  - F1-score: 98.63%
- **Metryki ogÃ³lne (weighted average):**
  - Precision: 98.46%
  - Recall: 98.97%
  - F1-score: 98.63%

### Obserwacje:
- Model osiÄ…ga **98.97% accuracy** na zbiorze testowym (bardzo dobry wynik!)
- **Top-2 accuracy: 100%** - prawidÅ‚owa odpowiedÅº jest zawsze w top 2 predykcji
- Dla top 50 klas (najczÄ™Å›ciej wystÄ™pujÄ…cych) accuracy wynosi 100%
- **GÅ‚Ã³wne problemy:** Tylko 2 pary klas sÄ… mylone:
  - Chad â†’ Romania (15 bÅ‚Ä™dÃ³w, 100% bÅ‚Ä™dÃ³w dla Chad)
  - Indonesia â†’ Monaco (15 bÅ‚Ä™dÃ³w, 100% bÅ‚Ä™dÃ³w dla Indonesia)
- **Dlaczego te bÅ‚Ä™dy?** Flagi sÄ… wizualnie niemal identyczne:
  - Chad vs Romania: RÃ³Å¼niÄ… siÄ™ tylko odcieniem niebieskiego
  - Indonesia vs Monaco: Identyczne flagi (rÃ³Å¼ne tylko proporcje)
- **PewnoÅ›Ä‡ modelu:** Model ma niskÄ… pewnoÅ›Ä‡ (~51-56%) przy bÅ‚Ä™dach, co wskazuje na Å›wiadomoÅ›Ä‡ niepewnoÅ›ci
- **193 z 195 klas:** MajÄ… 100% accuracy (perfekcyjna klasyfikacja)

### Status: ZakoÅ„czony

---

## ETAP 5: Optymalizacja [ZREALIZOWANY]

### Zadania wykonane:
- âœ… **ETAP 5A: ZwiÄ™kszenie liczby prÃ³bek**
  - ZwiÄ™kszono z 50 do 75 prÃ³bek na klasÄ™
  - WiÄ™cej danych = lepsze wyniki
- âœ… **ETAP 5B: Przetestowanie augmentacji danych**
  - Zaimplementowano augmentacjÄ™ (obrÃ³t, przesuniÄ™cie, jasnoÅ›Ä‡, zoom)
  - **Wynik testu:** Augmentacja powodowaÅ‚a spadek accuracy (1.54% z augmentacjÄ… vs 99.49% bez)
  - **Decyzja:** Augmentacja wyÅ‚Ä…czona - dla tego zadania nie byÅ‚a potrzebna
  - **SzczegÃ³Å‚y prÃ³by:** Zobacz sekcjÄ™ "PrÃ³ba z augmentacjÄ… danych" poniÅ¼ej
- â­ï¸ **ETAP 5C: Eksperymenty z hiperparametrami** (opcjonalnie, pominiÄ™te)
  - Model osiÄ…ga juÅ¼ doskonaÅ‚e wyniki (99.49%), wiÄ™c dalsze optymalizacje nie byÅ‚y konieczne

### Pliki:
- `train.py` - zaktualizowany (75 prÃ³bek, augmentacja wyÅ‚Ä…czona)
- `evaluate.py` - zaktualizowany (75 prÃ³bek)
- `models/best_model.h5` - nowy model wytrenowany na 75 prÃ³bkach/klasÄ™

### Wyniki optymalizacji (finalne):
- **Test Accuracy:** 98.97% (poprzednio: 93.85% z 50 prÃ³bkami)
- **Top-2 Accuracy:** 100.00% â­
- **Top-3 Accuracy:** 100.00%
- **Test Loss:** 0.0264
- **BÅ‚Ä™dy:** 30 / 2925 (1.03%)
- **Wzrost accuracy:** +5.12% (z 93.85% do 98.97%)
- **Dodatkowe ulepszenia:**
  - Learning Rate Scheduler (ReduceLROnPlateau) - automatyczna optymalizacja LR
  - 6 wykresÃ³w analitycznych z treningu (obserwacja procesu uczenia)
  - 9 wykresÃ³w analitycznych z ewaluacji (szczegÃ³Å‚owa analiza wynikÃ³w)

### Wnioski:
1. **WiÄ™cej danych pomaga:** ZwiÄ™kszenie z 50 do 75 prÃ³bek/klasÄ™ poprawiÅ‚o wyniki (+5.12%)
2. **Augmentacja nie zawsze pomaga:** W tym przypadku powodowaÅ‚a spadek accuracy, wiÄ™c zostaÅ‚a wyÅ‚Ä…czona
3. **Learning Rate Scheduler pomaga:** ReduceLROnPlateau automatycznie optymalizuje learning rate podczas treningu
4. **Model dziaÅ‚a doskonale:** 98.97% accuracy to bardzo dobry wynik dla 195 klas
5. **Top-2 accuracy 100%:** Nawet gdy model siÄ™ myli, prawidÅ‚owa odpowiedÅº jest zawsze w top 2 predykcji
6. **BÅ‚Ä™dy sÄ… przewidywalne:** Wszystkie bÅ‚Ä™dy dotyczÄ… wizualnie bardzo podobnych flag (Chad-Romania, Indonesia-Monaco)

---

### PrÃ³ba z augmentacjÄ… danych (ETAP 5B - szczegÃ³Å‚y)

#### Co byÅ‚o testowane:
Zaimplementowano augmentacjÄ™ danych uÅ¼ywajÄ…c `ImageDataGenerator` z nastÄ™pujÄ…cymi parametrami:
- **ObrÃ³t:** Â±10 stopni (`rotation_range=10`)
- **PrzesuniÄ™cie poziome:** Â±10% (`width_shift_range=0.1`)
- **PrzesuniÄ™cie pionowe:** Â±10% (`height_shift_range=0.1`)
- **JasnoÅ›Ä‡:** Â±20% (`brightness_range=[0.8, 1.2]`)
- **Zoom:** Â±10% (`zoom_range=0.1`)
- **Fill mode:** `nearest` (wypeÅ‚nianie pikseli przy transformacjach)
- **Rescale:** `1.0` (dane juÅ¼ znormalizowane do [0,1])

#### Wyniki testÃ³w:

**Z augmentacjÄ…:**
- Train accuracy: 1-19% (bardzo niska, rosÅ‚a powoli)
- Val accuracy: 1.03% (epoka 1), potem spadaÅ‚a do 0%
- Test accuracy: 1.54%
- Val loss: 5.67 â†’ 19.41 (bardzo wysoki, rosnÄ…cy)
- Problem: Model siÄ™ nie uczyÅ‚ poprawnie, generator koÅ„czyÅ‚ siÄ™ za wczeÅ›nie

**Bez augmentacji:**
- Train accuracy: 21% â†’ 98% (szybki wzrost)
- Val accuracy: 7.18% â†’ 99.49% (epoka 8)
- Test accuracy: 99.49%
- Val loss: 5.32 â†’ 0.0089 (szybki spadek)
- Sukces: Model uczyÅ‚ siÄ™ poprawnie i osiÄ…gnÄ…Å‚ doskonaÅ‚e wyniki

#### MoÅ¼liwe przyczyny problemu z augmentacjÄ…:

1. **Zbyt agresywne transformacje dla flag:**
   - Flagi majÄ… specyficznÄ… geometriÄ™ (proporcje, kolory, wzory)
   - ObrÃ³t Â±10Â° moÅ¼e zmieniÄ‡ orientacjÄ™ flagi (np. flaga pionowa vs pozioma)
   - PrzesuniÄ™cia mogÄ… przyciÄ…Ä‡ waÅ¼ne elementy flagi

2. **Problem z generatorami danych:**
   - Generator koÅ„czyÅ‚ siÄ™ za wczeÅ›nie ("Your input ran out of data")
   - MoÅ¼liwe problemy z `steps_per_epoch` lub synchronizacjÄ… generatorÃ³w

3. **Normalizacja danych:**
   - Dane juÅ¼ byÅ‚y znormalizowane do [0,1]
   - `rescale=1.0` w generatorze moÅ¼e powodowaÄ‡ konflikty

4. **Zbyt maÅ‚o danych:**
   - 75 prÃ³bek/klasÄ™ moÅ¼e byÄ‡ za maÅ‚o dla skutecznej augmentacji
   - Augmentacja dziaÅ‚a lepiej przy wiÄ™kszych zbiorach danych

#### Co moÅ¼na sprÃ³bowaÄ‡ w przyszÅ‚oÅ›ci:

1. **Mniej agresywne transformacje:**
   - ObrÃ³t: Â±5Â° zamiast Â±10Â°
   - PrzesuniÄ™cia: Â±5% zamiast Â±10%
   - WyÅ‚Ä…czyÄ‡ zoom (flagi majÄ… staÅ‚e proporcje)

2. **Selektywna augmentacja:**
   - Tylko jasnoÅ›Ä‡ i kontrast (bez obrotÃ³w/przesuniÄ™Ä‡)
   - Augmentacja tylko dla niektÃ³rych klas

3. **WiÄ™cej danych:**
   - ZwiÄ™kszyÄ‡ do 100-200 prÃ³bek/klasÄ™ przed zastosowaniem augmentacji

4. **Inne metody augmentacji:**
   - Cutout/CutMix
   - Mixup
   - Specjalne transformacje dla flag (np. zmiana kolorÃ³w w okreÅ›lonych zakresach)

5. **Poprawa generatorÃ³w:**
   - UÅ¼yÄ‡ `.repeat()` w generatorach
   - SprawdziÄ‡ synchronizacjÄ™ miÄ™dzy train i validation generatorami
   - UÅ¼yÄ‡ bezpoÅ›rednio tablic dla validation (jak w finalnej wersji)

#### Status prÃ³by:
- **PrÃ³ba:** Zrealizowana i udokumentowana
- **Wynik:** Niepowodzenie - augmentacja powodowaÅ‚a spadek accuracy
- **Decyzja:** Augmentacja wyÅ‚Ä…czona w finalnej wersji
- **MoÅ¼liwoÅ›Ä‡ powrotu:** Tak - moÅ¼na wrÃ³ciÄ‡ do tego w przyszÅ‚oÅ›ci z mniej agresywnymi parametrami

---

### Status: ZakoÅ„czony

---

## ETAP 6: Sprawozdanie

### ZawartoÅ›Ä‡ sprawozdania:
- Opis problemu i zbioru danych
- Opis przygotowania danych (ETAP 1)
- Opis architektury modelu (ETAP 2)
- Obserwacje procesu uczenia:
  - Wykresy loss i accuracy
  - Analiza zbieÅ¼noÅ›ci
  - Problemy napotkane i rozwiÄ…zania
- Wyniki i wnioski:
  - DokÅ‚adnoÅ›Ä‡ modelu na zbiorze testowym
  - Analiza bÅ‚Ä™dÃ³w
  - Wnioski koÅ„cowe

### Pliki:
- Dokumentacja/sprawozdanie w formacie Markdown lub PDF

---

## PodziaÅ‚ pracy miÄ™dzy czÅ‚onkÃ³w zespoÅ‚u

### Proponowany podziaÅ‚:
- **Osoba 1**: ETAP 2 (Model) + ETAP 3 (Trening)
- **Osoba 2**: ETAP 4 (Ewaluacja) + ETAP 6 (Sprawozdanie - czÄ™Å›Ä‡ wynikÃ³w)
- **Osoba 3**: ETAP 5 (Optymalizacja) + ETAP 6 (Sprawozdanie - czÄ™Å›Ä‡ analizy)

### Uwaga:
ETAP 1 jest juÅ¼ zrealizowany i moÅ¼e byÄ‡ uÅ¼ywany przez wszystkich. KaÅ¼dy powinien mieÄ‡ dostÄ™p do danych i mÃ³c uruchomiÄ‡ `load_data.py`.

---

## NajwaÅ¼niejsze etapy dla MVP

1. **ETAP 2** - Bez modelu nie ma co trenowaÄ‡
2. **ETAP 3** - Trening jest kluczowy dla dziaÅ‚ania systemu
3. **ETAP 4** - Ewaluacja pokazuje czy projekt dziaÅ‚a

ETAP 5 i 6 sÄ… waÅ¼ne dla jakoÅ›ci projektu, ale MVP moÅ¼na zrealizowaÄ‡ bez optymalizacji.

---

## Aktualny status

- ETAP 1: ZakoÅ„czony âœ…
- ETAP 2: ZakoÅ„czony âœ…
- ETAP 3: ZakoÅ„czony âœ…
- ETAP 4: ZakoÅ„czony âœ…
- ETAP 5: ZakoÅ„czony âœ…
  - ETAP 5A: WiÄ™cej danych (50â†’75 prÃ³bek) âœ…
  - ETAP 5B: Przetestowanie augmentacji (wyÅ‚Ä…czona) âœ…
  - ETAP 5C: Eksperymenty z hiperparametrami (pominiÄ™te - niepotrzebne) â­ï¸
- ETAP 6: W kolejce (sprawozdanie)
