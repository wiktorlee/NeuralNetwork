# Etapy projektu - Klasyfikacja flag pa≈Ñstw

## Wymagania systemowe

### Wersje oprogramowania:
- **Python:** 3.11 lub 3.12 (zalecane 3.11 dla lepszej kompatybilno≈õci z TensorFlow)
- **TensorFlow:** >= 2.10.0
- **NumPy:** >= 1.22.0
- **Pillow:** >= 9.0.0
- **scikit-learn:** >= 1.0.0
- **matplotlib:** >= 3.5.0
- **seaborn:** >= 0.12.0
- **kagglehub:** >= 0.3.0
- **pandas:** >= 1.4.0 (opcjonalne)

**Uwaga:** Python 3.14 nie jest jeszcze wspierany przez TensorFlow. U≈ºyj Python 3.11 lub 3.12.

### Wymagania sprzƒôtowe:
- **RAM:** Minimum 4GB (zalecane 8GB+)
- **Dysk:** ~1GB wolnego miejsca (dane + model)
- **GPU:** Opcjonalne (przyspiesza trening, ale nie jest wymagane)

---

## Pierwsze uruchomienie ‚Äì kr√≥tkie instrukcje

### Lokalnie (na w≈Çasnym komputerze):
1. Utw√≥rz i aktywuj ≈õrodowisko: 
   - Windows: `py -3.11 -m venv .venv` oraz `.\.venv\Scripts\Activate.ps1`
   - Linux/Mac: `python3.11 -m venv .venv` oraz `source .venv/bin/activate`
2. Zainstaluj zale≈ºno≈õci: `pip install -r requirements.txt`.
3. Uruchom `test_etap1.py`, aby pobraƒá dane i potwierdziƒá, ≈ºe pipeline dzia≈Ça (to normalne, ≈ºe pobieranie zajmuje ~500‚ÄØMB i chwilƒô trwa).
4. Uruchom `model.py` (lub `test_model.py`), ≈ºeby sprawdziƒá, czy model buduje siƒô poprawnie.

### W Google Colab (szybszy trening dziƒôki GPU):
1. Otw√≥rz [Google Colab](https://colab.research.google.com/) i utw√≥rz nowy notebook.
2. W≈ÇƒÖcz GPU: **Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU ‚Üí Save**.
3. W pierwszej kom√≥rce zainstaluj zale≈ºno≈õci:
   ```python
   !pip install kagglehub tensorflow matplotlib scikit-learn pillow numpy
   ```
4. Prze≈õlij pliki projektu: kliknij ikonƒô folderu (üìÅ Files) po lewej ‚Üí **Upload to session storage** ‚Üí wybierz `train.py`, `model.py`, `load_data.py`.
5. Uruchom trening w nowej kom√≥rce:
   ```python
   !python /content/train.py
   ```
6. Po zako≈Ñczeniu treningu pobierz wyniki: **Files ‚Üí models/best_model.h5** (prawym ‚Üí Download) oraz **plots/training_history.png**.
   
**Uwaga:** Trening w Colab na GPU trwa ~5-10 minut (vs ~75 minut na CPU lokalnie). Dane i wyniki sƒÖ przechowywane tylko podczas sesji Colab.

## Cel projektu
Zbudowanie systemu klasyfikacji obraz√≥w flag pa≈Ñstw ≈õwiata u≈ºywajƒÖc sieci neuronowych g≈Çƒôbokich. Zbi√≥r danych zawiera 195 kraj√≥w, po oko≈Ço 1001 obraz√≥w na kraj.

## MVP - Minimalna wersja dzia≈ÇajƒÖca
System zdolny do klasyfikacji flag z dok≈Çadno≈õciƒÖ powy≈ºej 50% na zbiorze testowym, z pe≈Çnym pipeline od pobrania danych do ewaluacji modelu.

---

## ETAP 1: Pobieranie i przygotowanie danych [ZREALIZOWANY]

### Zadania wykonane:
- Implementacja automatycznego pobierania danych z Kaggle (kagglehub)
- Wczytywanie obraz√≥w z folder√≥w zorganizowanych wed≈Çug kraj√≥w
- Preprocessing:
  - Konwersja do RGB
  - Zmiana rozmiaru do 128x128 pikseli
  - Normalizacja warto≈õci pikseli do zakresu [0, 1]
- Podzia≈Ç danych na zbiory: train (70%), validation (10%), test (20%)

### Pliki:
- `download_data.py` - pobieranie danych z Kaggle
- `load_data.py` - wczytywanie i preprocessing danych
- `requirements.txt` - lista zale≈ºno≈õci Python

### Status: Zako≈Ñczony

---

## ETAP 2: Projektowanie i implementacja modelu [ZREALIZOWANY]

### Zadania:
- Zaprojektowanie architektury CNN odpowiedniej dla 195 klas
- Implementacja modelu w TensorFlow/Keras
- Wyb√≥r warstw:
  - Warstwy konwolucyjne (Conv2D)
  - Warstwy pooling (MaxPooling2D)
  - Warstwy dropout dla regularyzacji
  - Warstwy gƒôste (Dense)
  - Warstwa wyj≈õciowa z softmax
- Kompilacja modelu z odpowiednim optimizer i loss function
- Test czy model siƒô kompiluje i ma poprawny kszta≈Çt wyj≈õciowy

### Pliki:
- `model.py` - definicja architektury CNN + sekcja testowa w `__main__`
- `test_model.py` - sanity check kszta≈Çtu i softmaxu

### Kryteria sukcesu:
- Model kompiluje siƒô bez b≈Çƒôd√≥w
- Kszta≈Çt wyj≈õciowy: (batch_size, 195)
- Model gotowy do treningu

---

## ETAP 3: Trening modelu [ZREALIZOWANY]

### Zadania wykonane:
- ‚úÖ Implementacja skryptu treningowego (`train.py`)
- ‚úÖ Konfiguracja hiperparametr√≥w:
  - Learning rate: `1e-3` (Adam optimizer)
  - Batch size: `32`
  - Maksymalna liczba epok: `30`
  - EarlyStopping patience: `5`
  - Liczba pr√≥bek na klasƒô: `50` (dla Colab, mo≈ºna zmieniƒá w `train.py`)
- ‚úÖ Implementacja callbacks:
  - **ModelCheckpoint** - zapisywanie najlepszego modelu (`models/best_model.h5`) na podstawie `val_accuracy`
  - **EarlyStopping** - zatrzymanie przy braku poprawy przez 5 epok, przywr√≥cenie najlepszych wag
- ‚úÖ Wizualizacja procesu uczenia:
  - Wykres accuracy (train vs validation) - `plots/training_history.png`
  - Wykres loss (train vs validation) - `plots/training_history.png`
- ‚úÖ Zapis wytrenowanego modelu: `models/best_model.h5`

### Pliki:
- `train.py` - skrypt treningowy z funkcjami modu≈Çowymi
- `models/best_model.h5` - wytrenowany model (najlepsza wersja)
- `plots/training_history.png` - wykresy historii treningu

### Wyniki treningu:
- **Val accuracy:** 99.57% (epoka 11 - najlepsza)
- **Train accuracy:** 98.83% (epoka 11)
- **Liczba epok:** 16 (zatrzymane przez EarlyStopping)
- **Czas treningu:** ~5-10 minut na GPU (Colab), ~75 minut na CPU (lokalnie)
- **Zbie≈ºno≈õƒá:** Szybka zbie≈ºno≈õƒá od epoki 4, brak overfittingu

### Parametry u≈ºyte w treningu:
```python
batch_size=32
epochs=30
learning_rate=1e-3
patience=5
max_samples_per_class=50  # ~5,850 obraz√≥w (30 na klasƒô √ó 195 klas)
```

### Status: Zako≈Ñczony

---

## ETAP 4: Ewaluacja modelu [ZREALIZOWANY]

### Zadania wykonane:
- ‚úÖ Ewaluacja na zbiorze testowym:
  - Obliczenie accuracy i loss
  - Confusion matrix
- ‚úÖ Analiza b≈Çƒôd√≥w:
  - Kt√≥re flagi sƒÖ najtrudniejsze do rozpoznania
  - Przyk≈Çady b≈Çƒôdnych klasyfikacji
  - Wizualizacja confusion matrix
- ‚úÖ Obliczenie metryk szczeg√≥≈Çowych:
  - Precision, Recall, F1-score per class
  - Top-3 accuracy

### Pliki:
- `evaluate.py` - skrypt ewaluacji
- `plots/confusion_matrix_top_classes.png` - wizualizacja confusion matrix (top 50 klas)
- `plots/confusion_matrix.txt` - surowe dane confusion matrix
- `plots/error_analysis.txt` - analiza najtrudniejszych klas
- `plots/error_examples.png` - przyk≈Çady b≈Çƒôdnych klasyfikacji
- `plots/classification_report.txt` - szczeg√≥≈Çowy raport z metrykami per class

### Wyniki ewaluacji:
- **Test Accuracy:** 93.85%
- **Test Loss:** 1.47
- **Top-3 Accuracy:** 94.36%
- **Liczba b≈Çƒôd√≥w:** 120 / 1950 (6.15%)
- **Metryki og√≥lne (macro average):**
  - Precision: 93.59%
  - Recall: 93.85%
  - F1-score: 93.68%
- **Metryki og√≥lne (weighted average):**
  - Precision: 93.59%
  - Recall: 93.85%
  - F1-score: 93.68%

### Obserwacje:
- Model osiƒÖga 93.85% accuracy na zbiorze testowym
- Dla top 50 klas (najczƒô≈õciej wystƒôpujƒÖcych) accuracy wynosi 100%
- G≈Ç√≥wne problemy: podobne flagi sƒÖ mylone (np. Chad-Romania, Dominican Republic-DRC)
- Wiele klas z 100% b≈Çƒôd√≥w wynika z ma≈Çej liczby pr√≥bek w test set (10 pr√≥bek na klasƒô)
- Model jest bardzo pewny swoich predykcji, nawet przy b≈Çƒôdach (pewno≈õƒá 87-100%)

### Status: Zako≈Ñczony

---

## ETAP 5: Optymalizacja (opcjonalnie)

### Zadania:
- Eksperymenty z hiperparametrami
- Augmentacja danych (obroty, przesuniƒôcia, zmiana jasno≈õci/kontrastu)
- Transfer learning (u≈ºycie pre-trenowanych modeli jak ResNet, VGG)
- Por√≥wnanie r√≥≈ºnych architektur

### Pliki do stworzenia:
- `augment_data.py` - augmentacja danych (opcjonalnie)
- `train_advanced.py` - zaawansowany trening (opcjonalnie)

### Uwaga:
Ten etap jest opcjonalny i zale≈ºy od wynik√≥w z etapu 4. Je≈õli podstawowy model osiƒÖga zadowalajƒÖce wyniki, mo≈ºna go pominƒÖƒá.

---

## ETAP 6: Sprawozdanie

### Zawarto≈õƒá sprawozdania:
- Opis problemu i zbioru danych
- Opis przygotowania danych (ETAP 1)
- Opis architektury modelu (ETAP 2)
- Obserwacje procesu uczenia:
  - Wykresy loss i accuracy
  - Analiza zbie≈ºno≈õci
  - Problemy napotkane i rozwiƒÖzania
- Wyniki i wnioski:
  - Dok≈Çadno≈õƒá modelu na zbiorze testowym
  - Analiza b≈Çƒôd√≥w
  - Wnioski ko≈Ñcowe

### Pliki:
- Dokumentacja/sprawozdanie w formacie Markdown lub PDF

---

## Podzia≈Ç pracy miƒôdzy cz≈Çonk√≥w zespo≈Çu

### Proponowany podzia≈Ç:
- **Osoba 1**: ETAP 2 (Model) + ETAP 3 (Trening)
- **Osoba 2**: ETAP 4 (Ewaluacja) + ETAP 6 (Sprawozdanie - czƒô≈õƒá wynik√≥w)
- **Osoba 3**: ETAP 5 (Optymalizacja) + ETAP 6 (Sprawozdanie - czƒô≈õƒá analizy)

### Uwaga:
ETAP 1 jest ju≈º zrealizowany i mo≈ºe byƒá u≈ºywany przez wszystkich. Ka≈ºdy powinien mieƒá dostƒôp do danych i m√≥c uruchomiƒá `load_data.py`.

---

## Najwa≈ºniejsze etapy dla MVP

1. **ETAP 2** - Bez modelu nie ma co trenowaƒá
2. **ETAP 3** - Trening jest kluczowy dla dzia≈Çania systemu
3. **ETAP 4** - Ewaluacja pokazuje czy projekt dzia≈Ça

ETAP 5 i 6 sƒÖ wa≈ºne dla jako≈õci projektu, ale MVP mo≈ºna zrealizowaƒá bez optymalizacji.

---

## Aktualny status

- ETAP 1: Zako≈Ñczony ‚úÖ
- ETAP 2: Zako≈Ñczony ‚úÖ
- ETAP 3: Zako≈Ñczony ‚úÖ
- ETAP 4: Zako≈Ñczony ‚úÖ
- ETAP 5: W kolejce (opcjonalny)
- ETAP 6: W kolejce (sprawozdanie)
