# Etapy projektu - Klasyfikacja flag paÅ„stw

## Wymagania systemowe

### Wersje oprogramowania:
- **Python:** 3.11 lub 3.12 (zalecane 3.11 dla lepszej kompatybilnoÅ›ci z TensorFlow)
- **TensorFlow:** >= 2.10.0
- **NumPy:** >= 1.22.0
- **Pillow:** >= 9.0.0
- **scikit-learn:** >= 1.0.0
- **matplotlib:** >= 3.5.0
- **seaborn:** >= 0.12.0
- **kagglehub:** >= 0.3.0
- **pandas:** >= 1.4.0 (opcjonalne)

**Uwaga:** Python 3.14 nie jest jeszcze wspierany przez TensorFlow. UÅ¼yj Python 3.11 lub 3.12.

### Wymagania sprzÄ™towe:
- **RAM:** Minimum 4GB (zalecane 8GB+)
- **Dysk:** ~1GB wolnego miejsca (dane + model)
- **GPU:** Opcjonalne (przyspiesza trening, ale nie jest wymagane)

---

## Pierwsze uruchomienie â€“ krÃ³tkie instrukcje

### Lokalnie (na wÅ‚asnym komputerze):
1. UtwÃ³rz i aktywuj Å›rodowisko: 
   - Windows: `py -3.11 -m venv .venv` oraz `.\.venv\Scripts\Activate.ps1`
   - Linux/Mac: `python3.11 -m venv .venv` oraz `source .venv/bin/activate`
2. Zainstaluj zaleÅ¼noÅ›ci: `pip install -r requirements.txt`.
3. Uruchom `test_etap1.py`, aby pobraÄ‡ dane i potwierdziÄ‡, Å¼e pipeline dziaÅ‚a (to normalne, Å¼e pobieranie zajmuje ~500â€¯MB i chwilÄ™ trwa).
4. Uruchom `model.py` (lub `test_model.py`), Å¼eby sprawdziÄ‡, czy model buduje siÄ™ poprawnie.

### W Google Colab (szybszy trening dziÄ™ki GPU):
1. OtwÃ³rz [Google Colab](https://colab.research.google.com/) i utwÃ³rz nowy notebook.
2. WÅ‚Ä…cz GPU: **Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU â†’ Save**.
3. W pierwszej komÃ³rce zainstaluj zaleÅ¼noÅ›ci:
   ```python
   !pip install kagglehub tensorflow matplotlib scikit-learn pillow numpy
   ```
4. PrzeÅ›lij pliki projektu: kliknij ikonÄ™ folderu (ğŸ“ Files) po lewej â†’ **Upload to session storage** â†’ wybierz `train.py`, `model.py`, `load_data.py`.
5. Uruchom trening w nowej komÃ³rce:
   ```python
   !python /content/train.py
   ```
6. Po zakoÅ„czeniu treningu pobierz wyniki: **Files â†’ models/best_model.h5** (prawym â†’ Download) oraz **plots/training_history.png**.
   
**Uwaga:** Trening w Colab na GPU trwa ~5-10 minut (vs ~75 minut na CPU lokalnie). Dane i wyniki sÄ… przechowywane tylko podczas sesji Colab.

## Cel projektu
Zbudowanie systemu klasyfikacji obrazÃ³w flag paÅ„stw Å›wiata uÅ¼ywajÄ…c sieci neuronowych gÅ‚Ä™bokich. ZbiÃ³r danych zawiera 195 krajÃ³w, po okoÅ‚o 1001 obrazÃ³w na kraj.

## MVP - Minimalna wersja dziaÅ‚ajÄ…ca
System zdolny do klasyfikacji flag z dokÅ‚adnoÅ›ciÄ… powyÅ¼ej 50% na zbiorze testowym, z peÅ‚nym pipeline od pobrania danych do ewaluacji modelu.

---

## ETAP 1: Pobieranie i przygotowanie danych [ZREALIZOWANY]

### Zadania wykonane:
- Implementacja automatycznego pobierania danych z Kaggle (kagglehub)
- Wczytywanie obrazÃ³w z folderÃ³w zorganizowanych wedÅ‚ug krajÃ³w
- Preprocessing:
  - Konwersja do RGB
  - Zmiana rozmiaru do 128x128 pikseli
  - Normalizacja wartoÅ›ci pikseli do zakresu [0, 1]
- PodziaÅ‚ danych na zbiory: train (70%), validation (10%), test (20%)

### Pliki:
- `download_data.py` - pobieranie danych z Kaggle
- `load_data.py` - wczytywanie i preprocessing danych
- `requirements.txt` - lista zaleÅ¼noÅ›ci Python

### Status: ZakoÅ„czony

---

## ETAP 2: Projektowanie i implementacja modelu [ZREALIZOWANY]

### Zadania:
- Zaprojektowanie architektury CNN odpowiedniej dla 195 klas
- Implementacja modelu w TensorFlow/Keras
- WybÃ³r warstw:
  - Warstwy konwolucyjne (Conv2D)
  - Warstwy pooling (MaxPooling2D)
  - Warstwy dropout dla regularyzacji
  - Warstwy gÄ™ste (Dense)
  - Warstwa wyjÅ›ciowa z softmax
- Kompilacja modelu z odpowiednim optimizer i loss function
- Test czy model siÄ™ kompiluje i ma poprawny ksztaÅ‚t wyjÅ›ciowy

### Pliki:
- `model.py` - definicja architektury CNN + sekcja testowa w `__main__`
- `test_model.py` - sanity check ksztaÅ‚tu i softmaxu

### Kryteria sukcesu:
- Model kompiluje siÄ™ bez bÅ‚Ä™dÃ³w
- KsztaÅ‚t wyjÅ›ciowy: (batch_size, 195)
- Model gotowy do treningu

---

## ETAP 3: Trening modelu [ZREALIZOWANY]

### Zadania wykonane:
- âœ… Implementacja skryptu treningowego (`train.py`)
- âœ… Konfiguracja hiperparametrÃ³w:
  - Learning rate: `1e-3` (Adam optimizer)
  - Batch size: `32`
  - Maksymalna liczba epok: `30`
  - EarlyStopping patience: `5`
  - Liczba prÃ³bek na klasÄ™: `50` (dla Colab, moÅ¼na zmieniÄ‡ w `train.py`)
- âœ… Implementacja callbacks:
  - **ModelCheckpoint** - zapisywanie najlepszego modelu (`models/best_model.h5`) na podstawie `val_accuracy`
  - **EarlyStopping** - zatrzymanie przy braku poprawy przez 5 epok, przywrÃ³cenie najlepszych wag
- âœ… Wizualizacja procesu uczenia:
  - Wykres accuracy (train vs validation) - `plots/training_history.png`
  - Wykres loss (train vs validation) - `plots/training_history.png`
- âœ… Zapis wytrenowanego modelu: `models/best_model.h5`

### Pliki:
- `train.py` - skrypt treningowy z funkcjami moduÅ‚owymi
- `models/best_model.h5` - wytrenowany model (najlepsza wersja)
- `plots/training_history.png` - wykresy historii treningu

### Wyniki treningu:
- **Val accuracy:** 99.57% (epoka 11 - najlepsza)
- **Train accuracy:** 98.83% (epoka 11)
- **Liczba epok:** 16 (zatrzymane przez EarlyStopping)
- **Czas treningu:** ~5-10 minut na GPU (Colab), ~75 minut na CPU (lokalnie)
- **ZbieÅ¼noÅ›Ä‡:** Szybka zbieÅ¼noÅ›Ä‡ od epoki 4, brak overfittingu

### Parametry uÅ¼yte w treningu:
```python
batch_size=32
epochs=30
learning_rate=1e-3
patience=5
max_samples_per_class=50  # ~5,850 obrazÃ³w (30 na klasÄ™ Ã— 195 klas)
```

### Status: ZakoÅ„czony

---

## ETAP 4: Ewaluacja modelu [ZREALIZOWANY]

### Zadania wykonane:
- âœ… Ewaluacja na zbiorze testowym:
  - Obliczenie accuracy i loss
  - Confusion matrix
- âœ… Analiza bÅ‚Ä™dÃ³w:
  - KtÃ³re flagi sÄ… najtrudniejsze do rozpoznania
  - PrzykÅ‚ady bÅ‚Ä™dnych klasyfikacji
  - Wizualizacja confusion matrix
- âœ… Obliczenie metryk szczegÃ³Å‚owych:
  - Precision, Recall, F1-score per class
  - Top-3 accuracy

### Pliki:
- `evaluate.py` - skrypt ewaluacji
- `plots/confusion_matrix_top_classes.png` - wizualizacja confusion matrix (top 50 klas)
- `plots/confusion_matrix.txt` - surowe dane confusion matrix
- `plots/error_analysis.txt` - analiza najtrudniejszych klas
- `plots/error_examples.png` - przykÅ‚ady bÅ‚Ä™dnych klasyfikacji
- `plots/classification_report.txt` - szczegÃ³Å‚owy raport z metrykami per class

### Wyniki ewaluacji:
- **Test Accuracy:** 93.85%
- **Test Loss:** 1.47
- **Top-3 Accuracy:** 94.36%
- **Liczba bÅ‚Ä™dÃ³w:** 120 / 1950 (6.15%)
- **Metryki ogÃ³lne (macro average):**
  - Precision: 93.59%
  - Recall: 93.85%
  - F1-score: 93.68%
- **Metryki ogÃ³lne (weighted average):**
  - Precision: 93.59%
  - Recall: 93.85%
  - F1-score: 93.68%

### Obserwacje:
- Model osiÄ…ga 93.85% accuracy na zbiorze testowym
- Dla top 50 klas (najczÄ™Å›ciej wystÄ™pujÄ…cych) accuracy wynosi 100%
- GÅ‚Ã³wne problemy: podobne flagi sÄ… mylone (np. Chad-Romania, Dominican Republic-DRC)
- Wiele klas z 100% bÅ‚Ä™dÃ³w wynika z maÅ‚ej liczby prÃ³bek w test set (10 prÃ³bek na klasÄ™)
- Model jest bardzo pewny swoich predykcji, nawet przy bÅ‚Ä™dach (pewnoÅ›Ä‡ 87-100%)

### Status: ZakoÅ„czony

---

## ETAP 5: Optymalizacja [ZREALIZOWANY]

### Zadania wykonane:
- âœ… **ETAP 5A: ZwiÄ™kszenie liczby prÃ³bek**
  - ZwiÄ™kszono z 50 do 75 prÃ³bek na klasÄ™
  - WiÄ™cej danych = lepsze wyniki
- âœ… **ETAP 5B: Przetestowanie augmentacji danych**
  - Zaimplementowano augmentacjÄ™ (obrÃ³t, przesuniÄ™cie, jasnoÅ›Ä‡, zoom)
  - **Wynik testu:** Augmentacja powodowaÅ‚a spadek accuracy (1.54% z augmentacjÄ… vs 99.49% bez)
  - **Decyzja:** Augmentacja wyÅ‚Ä…czona - dla tego zadania nie byÅ‚a potrzebna
  - **SzczegÃ³Å‚y prÃ³by:** Zobacz sekcjÄ™ "PrÃ³ba z augmentacjÄ… danych" poniÅ¼ej
- â­ï¸ **ETAP 5C: Eksperymenty z hiperparametrami** (opcjonalnie, pominiÄ™te)
  - Model osiÄ…ga juÅ¼ doskonaÅ‚e wyniki (99.49%), wiÄ™c dalsze optymalizacje nie byÅ‚y konieczne

### Pliki:
- `train.py` - zaktualizowany (75 prÃ³bek, augmentacja wyÅ‚Ä…czona)
- `evaluate.py` - zaktualizowany (75 prÃ³bek)
- `models/best_model.h5` - nowy model wytrenowany na 75 prÃ³bkach/klasÄ™

### Wyniki optymalizacji:
- **Test Accuracy:** 99.49% (poprzednio: 93.85% z 50 prÃ³bkami)
- **Top-3 Accuracy:** 100.00%
- **Test Loss:** 0.0089
- **BÅ‚Ä™dy:** 15 / 2925 (0.51%)
- **Wzrost accuracy:** +5.64% (z 93.85% do 99.49%)

### Wnioski:
1. **WiÄ™cej danych pomaga:** ZwiÄ™kszenie z 50 do 75 prÃ³bek/klasÄ™ poprawiÅ‚o wyniki
2. **Augmentacja nie zawsze pomaga:** W tym przypadku powodowaÅ‚a spadek accuracy, wiÄ™c zostaÅ‚a wyÅ‚Ä…czona
3. **Model dziaÅ‚a doskonale:** 99.49% accuracy to bardzo dobry wynik dla 195 klas

---

### PrÃ³ba z augmentacjÄ… danych (ETAP 5B - szczegÃ³Å‚y)

#### Co byÅ‚o testowane:
Zaimplementowano augmentacjÄ™ danych uÅ¼ywajÄ…c `ImageDataGenerator` z nastÄ™pujÄ…cymi parametrami:
- **ObrÃ³t:** Â±10 stopni (`rotation_range=10`)
- **PrzesuniÄ™cie poziome:** Â±10% (`width_shift_range=0.1`)
- **PrzesuniÄ™cie pionowe:** Â±10% (`height_shift_range=0.1`)
- **JasnoÅ›Ä‡:** Â±20% (`brightness_range=[0.8, 1.2]`)
- **Zoom:** Â±10% (`zoom_range=0.1`)
- **Fill mode:** `nearest` (wypeÅ‚nianie pikseli przy transformacjach)
- **Rescale:** `1.0` (dane juÅ¼ znormalizowane do [0,1])

#### Wyniki testÃ³w:

**Z augmentacjÄ…:**
- Train accuracy: 1-19% (bardzo niska, rosÅ‚a powoli)
- Val accuracy: 1.03% (epoka 1), potem spadaÅ‚a do 0%
- Test accuracy: 1.54%
- Val loss: 5.67 â†’ 19.41 (bardzo wysoki, rosnÄ…cy)
- Problem: Model siÄ™ nie uczyÅ‚ poprawnie, generator koÅ„czyÅ‚ siÄ™ za wczeÅ›nie

**Bez augmentacji:**
- Train accuracy: 21% â†’ 98% (szybki wzrost)
- Val accuracy: 7.18% â†’ 99.49% (epoka 8)
- Test accuracy: 99.49%
- Val loss: 5.32 â†’ 0.0089 (szybki spadek)
- Sukces: Model uczyÅ‚ siÄ™ poprawnie i osiÄ…gnÄ…Å‚ doskonaÅ‚e wyniki

#### MoÅ¼liwe przyczyny problemu z augmentacjÄ…:

1. **Zbyt agresywne transformacje dla flag:**
   - Flagi majÄ… specyficznÄ… geometriÄ™ (proporcje, kolory, wzory)
   - ObrÃ³t Â±10Â° moÅ¼e zmieniÄ‡ orientacjÄ™ flagi (np. flaga pionowa vs pozioma)
   - PrzesuniÄ™cia mogÄ… przyciÄ…Ä‡ waÅ¼ne elementy flagi

2. **Problem z generatorami danych:**
   - Generator koÅ„czyÅ‚ siÄ™ za wczeÅ›nie ("Your input ran out of data")
   - MoÅ¼liwe problemy z `steps_per_epoch` lub synchronizacjÄ… generatorÃ³w

3. **Normalizacja danych:**
   - Dane juÅ¼ byÅ‚y znormalizowane do [0,1]
   - `rescale=1.0` w generatorze moÅ¼e powodowaÄ‡ konflikty

4. **Zbyt maÅ‚o danych:**
   - 75 prÃ³bek/klasÄ™ moÅ¼e byÄ‡ za maÅ‚o dla skutecznej augmentacji
   - Augmentacja dziaÅ‚a lepiej przy wiÄ™kszych zbiorach danych

#### Co moÅ¼na sprÃ³bowaÄ‡ w przyszÅ‚oÅ›ci:

1. **Mniej agresywne transformacje:**
   - ObrÃ³t: Â±5Â° zamiast Â±10Â°
   - PrzesuniÄ™cia: Â±5% zamiast Â±10%
   - WyÅ‚Ä…czyÄ‡ zoom (flagi majÄ… staÅ‚e proporcje)

2. **Selektywna augmentacja:**
   - Tylko jasnoÅ›Ä‡ i kontrast (bez obrotÃ³w/przesuniÄ™Ä‡)
   - Augmentacja tylko dla niektÃ³rych klas

3. **WiÄ™cej danych:**
   - ZwiÄ™kszyÄ‡ do 100-200 prÃ³bek/klasÄ™ przed zastosowaniem augmentacji

4. **Inne metody augmentacji:**
   - Cutout/CutMix
   - Mixup
   - Specjalne transformacje dla flag (np. zmiana kolorÃ³w w okreÅ›lonych zakresach)

5. **Poprawa generatorÃ³w:**
   - UÅ¼yÄ‡ `.repeat()` w generatorach
   - SprawdziÄ‡ synchronizacjÄ™ miÄ™dzy train i validation generatorami
   - UÅ¼yÄ‡ bezpoÅ›rednio tablic dla validation (jak w finalnej wersji)

#### Status prÃ³by:
- **PrÃ³ba:** Zrealizowana i udokumentowana
- **Wynik:** Niepowodzenie - augmentacja powodowaÅ‚a spadek accuracy
- **Decyzja:** Augmentacja wyÅ‚Ä…czona w finalnej wersji
- **MoÅ¼liwoÅ›Ä‡ powrotu:** Tak - moÅ¼na wrÃ³ciÄ‡ do tego w przyszÅ‚oÅ›ci z mniej agresywnymi parametrami

---

### Status: ZakoÅ„czony

---

## ETAP 6: Sprawozdanie

### ZawartoÅ›Ä‡ sprawozdania:
- Opis problemu i zbioru danych
- Opis przygotowania danych (ETAP 1)
- Opis architektury modelu (ETAP 2)
- Obserwacje procesu uczenia:
  - Wykresy loss i accuracy
  - Analiza zbieÅ¼noÅ›ci
  - Problemy napotkane i rozwiÄ…zania
- Wyniki i wnioski:
  - DokÅ‚adnoÅ›Ä‡ modelu na zbiorze testowym
  - Analiza bÅ‚Ä™dÃ³w
  - Wnioski koÅ„cowe

### Pliki:
- Dokumentacja/sprawozdanie w formacie Markdown lub PDF

---

## PodziaÅ‚ pracy miÄ™dzy czÅ‚onkÃ³w zespoÅ‚u

### Proponowany podziaÅ‚:
- **Osoba 1**: ETAP 2 (Model) + ETAP 3 (Trening)
- **Osoba 2**: ETAP 4 (Ewaluacja) + ETAP 6 (Sprawozdanie - czÄ™Å›Ä‡ wynikÃ³w)
- **Osoba 3**: ETAP 5 (Optymalizacja) + ETAP 6 (Sprawozdanie - czÄ™Å›Ä‡ analizy)

### Uwaga:
ETAP 1 jest juÅ¼ zrealizowany i moÅ¼e byÄ‡ uÅ¼ywany przez wszystkich. KaÅ¼dy powinien mieÄ‡ dostÄ™p do danych i mÃ³c uruchomiÄ‡ `load_data.py`.

---

## NajwaÅ¼niejsze etapy dla MVP

1. **ETAP 2** - Bez modelu nie ma co trenowaÄ‡
2. **ETAP 3** - Trening jest kluczowy dla dziaÅ‚ania systemu
3. **ETAP 4** - Ewaluacja pokazuje czy projekt dziaÅ‚a

ETAP 5 i 6 sÄ… waÅ¼ne dla jakoÅ›ci projektu, ale MVP moÅ¼na zrealizowaÄ‡ bez optymalizacji.

---

## Aktualny status

- ETAP 1: ZakoÅ„czony âœ…
- ETAP 2: ZakoÅ„czony âœ…
- ETAP 3: ZakoÅ„czony âœ…
- ETAP 4: ZakoÅ„czony âœ…
- ETAP 5: ZakoÅ„czony âœ…
  - ETAP 5A: WiÄ™cej danych (50â†’75 prÃ³bek) âœ…
  - ETAP 5B: Przetestowanie augmentacji (wyÅ‚Ä…czona) âœ…
  - ETAP 5C: Eksperymenty z hiperparametrami (pominiÄ™te - niepotrzebne) â­ï¸
- ETAP 6: W kolejce (sprawozdanie)
